# Taller-tercer-corte
punto 2: Este proyecto implementa el “Segundo Punto: Segmentación y clasificación de multímetro, osciloscopio y Raspberry Pi usando hilos, MediaPipe, Streamlit y Docker”; para reproducirlo, primero se clona el repositorio general en Ubuntu con `cd ~/Escritorio` y `git clone https://github.com/dialejobv/SistemasDigitales2025II.git`, luego se crea la carpeta del punto con `cd SistemasDigitales2025II` y `mkdir Punto2_Segmentacion && cd Punto2_Segmentacion`; dentro se arma el dataset mínimo creando `data/multimetro`, `data/osciloscopio` y `data/raspberry` y guardando en cada carpeta varias imágenes claras de cada dispositivo; después se crea el archivo `requirements.txt` con las dependencias `streamlit`, `opencv-python`, `mediapipe==0.10.11` y `numpy`; a continuación se genera `segmenter.py` con las funciones `aplicar_segmentacion(frame_bgr)` (que usa `mediapipe.solutions.selfie_segmentation` para calcular la máscara de primer plano pero devuelve el frame original sin modificar y una máscara booleana), `cargar_ejemplos()` (que recorre las carpetas `data/<clase>`, calcula el histograma HSV de cada imagen y guarda pares `(histograma, etiqueta)` en la lista global `ejemplos`), `_histograma_hsv(img_bgr, mask=None)` (que convierte a HSV, aplica opcionalmente la máscara binaria y calcula un histograma 2D H–S de 32×32 bins normalizado) y `clasificar_imagen(img_bgr, mask=None)` (que calcula el histograma de la región del objeto usando la máscara y busca por distancia euclidiana la clase más parecida entre los ejemplos, devolviendo la etiqueta ganadora); luego se crea `app.py`, una app de Streamlit que importa esas funciones, lanza dos hilos (`hilo_captura` y `hilo_procesamiento`) sincronizados con `Lock` y `Semaphore`: el primero abre la cámara con OpenCV (`cv2.VideoCapture(0)`), actualiza `frame_original` dentro de una sección crítica (`with lock_frame`) y libera el semáforo `sem_nuevo_frame`, el segundo espera frames nuevos (`sem_nuevo_frame.acquire()`), copia el frame bajo el lock, llama a `aplicar_segmentacion` para obtener imagen y máscara, clasifica con `clasificar_imagen(seg, mask=mask_objeto)`, escribe la etiqueta “Objeto: <clase>” sobre la imagen con `cv2.putText` y actualiza `frame_procesado` y `ultima_etiqueta`; en la parte Streamlit se llama una vez a `cargar_ejemplos()` (controlado con `st.session_state["ejemplos_cargados"]`), se arrancan los hilos solo la primera ejecución (`hilos_iniciados`), se crea un `placeholder_imagen` y `placeholder_texto` y en un bucle se muestra continuamente la imagen procesada (convertida a RGB) y la etiqueta detectada, usando un pequeño `time.sleep` para no saturar; para contenedorar la app se crea un `Dockerfile` con `FROM python:3.11-slim`, instalación de dependencias del sistema para OpenCV (`ffmpeg libsm6 libxext6`), `WORKDIR /app`, copia de `requirements.txt` y `pip install --no-cache-dir -r requirements.txt`, copia del resto del código, `EXPOSE 8501` y un `CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]`; con todo creado se construye la imagen desde `Punto2_Segmentacion` con `docker build -t punto2_segmentacion .` y, una vez finalizada, se ejecuta la aplicación montando la cámara con privilegios y red mapeada al puerto 8502 del host, por ejemplo `sudo docker run --rm -p 8502:8501 --privileged --device=/dev/video0 punto2_segmentacion` (o usando `/dev/video1` si la cámara está en ese dispositivo), tras lo cual se accede desde el navegador a `http://localhost:8502` para ver el video en vivo, con la segmentación lógica (vía máscara) y la etiqueta actualizada de multímetro, osciloscopio o Raspberry Pi calculada en paralelo por los hilos.
<img width="1301" height="685" alt="Captura desde 2025-11-22 01-35-56" src="https://github.com/user-attachments/assets/4ef85149-4eb9-48ff-ad26-5c6bce075bdc" />
<img width="1301" height="685" alt="Captura desde 2025-11-22 01-35-46" src="https://github.com/user-attachments/assets/0e215a94-c076-49be-b7c1-58f4f780aba7" />
<img width="1301" height="685" alt="Captura desde 2025-11-22 01-35-37" src="https://github.com/user-attachments/assets/3f02294a-ed01-4b12-99c6-615ae891e3fa" />
<img width="1301" height="685" alt="Captura desde 2025-11-22 01-35-23" src="https://github.com/user-attachments/assets/4c56931a-38a9-4007-bab2-22c65bd07731" />
<img width="1301" height="685" alt="Captura desde 2025-11-22 01-34-40" src="https://github.com/user-attachments/assets/2d94ccad-297b-4bb3-8187-fb3fea028f60" />
<img width="1301" height="652" alt="Captura desde 2025-11-22 00-41-54" src="https://github.com/user-attachments/assets/7c47aad0-d71c-4275-9fab-fb9c66bcdf07" />
<img width="1301" height="652" alt="Captura desde 2025-11-22 00-41-18" src="https://github.com/user-attachments/assets/4b228b97-c65a-4bd6-9f83-dff64ecf25f3" />
<img width="1301" height="652" alt="Captura desde 2025-11-22 00-40-43" src="https://github.com/user-attachments/assets/8fb54634-1877-4090-8c44-2f1cee0908e6" />
<img width="1301" height="652" alt="Captura desde 2025-11-22 00-40-34" src="https://github.com/user-attachments/assets/7c1f657e-de66-403b-97f6-3b0251011841" />
<img width="1301" height="652" alt="Captura desde 2025-11-22 00-39-20" src="https://github.com/user-attachments/assets/5d5f63f7-4899-4bc0-bb10-c1bb96b299c5" />
<img width="1301" height="652" alt="Captura desde 2025-11-22 00-39-11" src="https://github.com/user-attachments/assets/8160d704-b75b-43fa-943b-ce28f24f14e2" />

